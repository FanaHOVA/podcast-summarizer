{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "712fdefe-b4a9-4244-9c37-74cb3a179187",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (1.5.3)\n",
      "Requirement already satisfied: langchain in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (0.0.87)\n",
      "Requirement already satisfied: yt-dlp in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (2023.1.6)\n",
      "Requirement already satisfied: openai-whisper in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (20230124)\n",
      "Requirement already satisfied: python-dotenv in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.21.1)\n",
      "Requirement already satisfied: openai in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (0.26.5)\n",
      "Requirement already satisfied: tiktoken in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (0.2.0)\n",
      "Requirement already satisfied: nltk in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (3.8.1)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (1.21.6)\n",
      "Requirement already satisfied: chromadb in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (0.3.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 1)) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/homebrew/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/homebrew/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 2)) (3.8.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /opt/homebrew/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 2)) (1.10.5)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/homebrew/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 2)) (2.28.2)\n",
      "Requirement already satisfied: PyYAML<7,>=6 in /opt/homebrew/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 2)) (6.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/homebrew/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 2)) (8.2.1)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /opt/homebrew/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 2)) (0.5.7)\n",
      "Requirement already satisfied: SQLAlchemy<2,>=1 in /opt/homebrew/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 2)) (1.4.46)\n",
      "Requirement already satisfied: pycryptodomex in /opt/homebrew/lib/python3.10/site-packages (from yt-dlp->-r requirements.txt (line 3)) (3.17)\n",
      "Requirement already satisfied: brotli in /opt/homebrew/lib/python3.10/site-packages (from yt-dlp->-r requirements.txt (line 3)) (1.0.9)\n",
      "Requirement already satisfied: mutagen in /opt/homebrew/lib/python3.10/site-packages (from yt-dlp->-r requirements.txt (line 3)) (1.46.0)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/lib/python3.10/site-packages (from yt-dlp->-r requirements.txt (line 3)) (2022.12.7)\n",
      "Requirement already satisfied: websockets in /opt/homebrew/lib/python3.10/site-packages (from yt-dlp->-r requirements.txt (line 3)) (10.4)\n",
      "Requirement already satisfied: more-itertools in /opt/homebrew/lib/python3.10/site-packages (from openai-whisper->-r requirements.txt (line 4)) (9.0.0)\n",
      "Requirement already satisfied: torch in /opt/homebrew/lib/python3.10/site-packages (from openai-whisper->-r requirements.txt (line 4)) (1.13.1)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.10/site-packages (from openai-whisper->-r requirements.txt (line 4)) (4.64.1)\n",
      "Requirement already satisfied: ffmpeg-python==0.2.0 in /opt/homebrew/lib/python3.10/site-packages (from openai-whisper->-r requirements.txt (line 4)) (0.2.0)\n",
      "Requirement already satisfied: transformers>=4.19.0 in /opt/homebrew/lib/python3.10/site-packages (from openai-whisper->-r requirements.txt (line 4)) (4.26.1)\n",
      "Requirement already satisfied: future in /opt/homebrew/lib/python3.10/site-packages (from ffmpeg-python==0.2.0->openai-whisper->-r requirements.txt (line 4)) (0.18.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/homebrew/lib/python3.10/site-packages (from tiktoken->-r requirements.txt (line 7)) (2022.10.31)\n",
      "Requirement already satisfied: blobfile>=2 in /opt/homebrew/lib/python3.10/site-packages (from tiktoken->-r requirements.txt (line 7)) (2.0.1)\n",
      "Requirement already satisfied: click in /opt/homebrew/lib/python3.10/site-packages (from nltk->-r requirements.txt (line 8)) (8.1.3)\n",
      "Requirement already satisfied: joblib in /opt/homebrew/lib/python3.10/site-packages (from nltk->-r requirements.txt (line 8)) (1.2.0)\n",
      "Requirement already satisfied: uvicorn[standard]~=0.18.3 in /opt/homebrew/lib/python3.10/site-packages (from chromadb->-r requirements.txt (line 10)) (0.18.3)\n",
      "Requirement already satisfied: fastapi~=0.85.1 in /opt/homebrew/lib/python3.10/site-packages (from chromadb->-r requirements.txt (line 10)) (0.85.2)\n",
      "Requirement already satisfied: duckdb~=0.5.1 in /opt/homebrew/lib/python3.10/site-packages (from chromadb->-r requirements.txt (line 10)) (0.5.1)\n",
      "Requirement already satisfied: sentence-transformers~=2.2.2 in /opt/homebrew/lib/python3.10/site-packages (from chromadb->-r requirements.txt (line 10)) (2.2.2)\n",
      "Requirement already satisfied: hnswlib~=0.7 in /opt/homebrew/lib/python3.10/site-packages (from chromadb->-r requirements.txt (line 10)) (0.7.0)\n",
      "Requirement already satisfied: clickhouse-connect~=0.5.7 in /opt/homebrew/lib/python3.10/site-packages (from chromadb->-r requirements.txt (line 10)) (0.5.11)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2)) (22.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2)) (1.8.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2)) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2)) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2)) (3.0.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2)) (4.0.2)\n",
      "Requirement already satisfied: filelock~=3.0 in /opt/homebrew/lib/python3.10/site-packages (from blobfile>=2->tiktoken->-r requirements.txt (line 7)) (3.9.0)\n",
      "Requirement already satisfied: lxml~=4.9 in /opt/homebrew/lib/python3.10/site-packages (from blobfile>=2->tiktoken->-r requirements.txt (line 7)) (4.9.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.25.3 in /opt/homebrew/lib/python3.10/site-packages (from blobfile>=2->tiktoken->-r requirements.txt (line 7)) (1.26.14)\n",
      "Requirement already satisfied: lz4 in /opt/homebrew/lib/python3.10/site-packages (from clickhouse-connect~=0.5.7->chromadb->-r requirements.txt (line 10)) (4.3.2)\n",
      "Requirement already satisfied: zstandard in /opt/homebrew/lib/python3.10/site-packages (from clickhouse-connect~=0.5.7->chromadb->-r requirements.txt (line 10)) (0.19.0)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain->-r requirements.txt (line 2)) (0.8.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /opt/homebrew/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain->-r requirements.txt (line 2)) (1.5.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /opt/homebrew/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain->-r requirements.txt (line 2)) (3.19.0)\n",
      "Requirement already satisfied: starlette==0.20.4 in /opt/homebrew/lib/python3.10/site-packages (from fastapi~=0.85.1->chromadb->-r requirements.txt (line 10)) (0.20.4)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /opt/homebrew/lib/python3.10/site-packages (from starlette==0.20.4->fastapi~=0.85.1->chromadb->-r requirements.txt (line 10)) (3.6.2)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/homebrew/lib/python3.10/site-packages (from pydantic<2,>=1->langchain->-r requirements.txt (line 2)) (4.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.10/site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 2)) (3.4)\n",
      "Requirement already satisfied: torchvision in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers~=2.2.2->chromadb->-r requirements.txt (line 10)) (0.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers~=2.2.2->chromadb->-r requirements.txt (line 10)) (0.12.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers~=2.2.2->chromadb->-r requirements.txt (line 10)) (1.2.1)\n",
      "Requirement already satisfied: sentencepiece in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers~=2.2.2->chromadb->-r requirements.txt (line 10)) (0.1.97)\n",
      "Requirement already satisfied: scipy in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers~=2.2.2->chromadb->-r requirements.txt (line 10)) (1.10.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/lib/python3.10/site-packages (from transformers>=4.19.0->openai-whisper->-r requirements.txt (line 4)) (23.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/homebrew/lib/python3.10/site-packages (from transformers>=4.19.0->openai-whisper->-r requirements.txt (line 4)) (0.13.2)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/homebrew/lib/python3.10/site-packages (from uvicorn[standard]~=0.18.3->chromadb->-r requirements.txt (line 10)) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from uvicorn[standard]~=0.18.3->chromadb->-r requirements.txt (line 10)) (0.5.0)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/homebrew/lib/python3.10/site-packages (from uvicorn[standard]~=0.18.3->chromadb->-r requirements.txt (line 10)) (0.17.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /opt/homebrew/lib/python3.10/site-packages (from uvicorn[standard]~=0.18.3->chromadb->-r requirements.txt (line 10)) (0.18.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/homebrew/lib/python3.10/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain->-r requirements.txt (line 2)) (1.0.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn->sentence-transformers~=2.2.2->chromadb->-r requirements.txt (line 10)) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/homebrew/lib/python3.10/site-packages (from torchvision->sentence-transformers~=2.2.2->chromadb->-r requirements.txt (line 10)) (9.4.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/homebrew/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette==0.20.4->fastapi~=0.85.1->chromadb->-r requirements.txt (line 10)) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install -r requirements.txt\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d72b24e-45cf-45fc-b2ca-a947f3e1022f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=57OU18cogJI\n",
      "[youtube] 57OU18cogJI: Downloading webpage\n",
      "[youtube] 57OU18cogJI: Downloading android player API JSON\n",
      "[info] 57OU18cogJI: Downloading 1 format(s): 140\n",
      "[download] ./tmp/foo_StrictlyVC in conversation with Sam Altman, part one-57OU18cogJI.m4a has already been downloaded\n",
      "[download] 100% of   19.02MiB\n",
      "[ExtractAudio] Not converting audio ./tmp/foo_StrictlyVC in conversation with Sam Altman, part one-57OU18cogJI.m4a; file is already in target format m4a\n"
     ]
    }
   ],
   "source": [
    "import yt_dlp\n",
    "\n",
    "URLS = ['https://www.youtube.com/watch?v=57OU18cogJI']\n",
    "\n",
    "ydl_opts = {\n",
    "    'format': 'm4a/bestaudio/best',\n",
    "    'postprocessors': [{\n",
    "        'key': 'FFmpegExtractAudio',\n",
    "        'preferredcodec': 'm4a',\n",
    "    }],\n",
    "    'outtmpl': './tmp/foo_%(title)s-%(id)s.%(ext)s'\n",
    "}\n",
    "\n",
    "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "    error_code = ydl.download(URLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faa60d9e-147d-4914-b94e-b6ce864ca384",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import os\n",
    "import urllib.parse\n",
    "\n",
    "model = whisper.load_model(\"medium.en\")\n",
    "\n",
    "podcasts_to_analyze = {}\n",
    "\n",
    "for file in os.listdir(\"./tmp\"):\n",
    "    # Skip if the file is not a video or audio file\n",
    "    if not file.endswith(\".m4a\"):\n",
    "        continue\n",
    "    \n",
    "    file_path = os.path.join(\"./tmp\", file)\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        result = model.transcribe(file_path)\n",
    "        podcasts_to_analyze[file] = result[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d617b4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:Chroma:Logger created\n",
      "INFO:clickhouse_connect.driver.ctypes:Successfully imported ClickHouse Connect C data optimizations\n",
      "INFO:clickhouse_connect.driver.ctypes:Successfully import ClickHouse Connect C/Numpy optimizations\n",
      "INFO:clickhouse_connect.json_impl:Using python library for writing JSON byte strings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Chroma using direct local API.\n",
      "Using DuckDB in-memory for database. Data will be transient.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "chroma_client = chromadb.Client()\n",
    "\n",
    "collection = chroma_client.get_collection(name=\"oss_podcasts\") or chroma_client.create_collection(name=\"oss_podcasts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ede275e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for file, text in podcasts_to_analyze.items():\n",
    "    with open(f\"./podcasts/{urllib.parse.quote(file)}.txt\", \"w\") as f:\n",
    "        f.write(text)\n",
    "\n",
    "        collection.add(\n",
    "            documents=[text],\n",
    "            ids=[file]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3081ef70-f7c3-47d4-aefc-e1cd2b01aa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "\n",
    "template = \"\"\"\n",
    "Read the transcript of the podcast below:\n",
    " {podcast_contents}\n",
    "\n",
    "Create bullet points with the main topics of the podcast, followed by the opinions of the speakers. \n",
    "\"\"\"\n",
    "\n",
    "podcast_summary_prompt = PromptTemplate(\n",
    "    input_variables=[\"podcast_contents\"],\n",
    "    template=template,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adcd4686-0856-4392-923d-dce6d5834e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "\n",
    "template = \"\"\"\n",
    "When I listen to a podcast, I take notes on the main talking points of the hosts. I divide it in sections based on topics discussed. \n",
    "If the host mentions a specific technology or product, I note that in double brackets like this: [[artificial intelligence]].\n",
    "\n",
    "These are the notes from the last podcast I listened to:\n",
    "\n",
    "{podcast_notes}\n",
    "\n",
    "Write a {words_count} words summary of the notes.\n",
    "\"\"\"\n",
    "\n",
    "notes_summary_template = PromptTemplate(\n",
    "    input_variables=[\"podcast_notes\", \"words_count\"],\n",
    "    template=template,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9472a7e-ad26-469b-bd99-2904a4ec730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "\n",
    "template = \"\"\"\n",
    "When I take notes for a podcast, I like to also write twitter threads to share them. Each tweet should end saying how far we are in the thread; if it's a 5 tweets thread, the first tweet should end with (1/5), the second one with (2/5), etc.\n",
    "\n",
    "The tweets have to be easy to read and catch people's attention. Each of them should include an emoji.\n",
    "\n",
    "These are the notes from my last podcast:\n",
    "\n",
    "{podcast_notes}\n",
    "\n",
    "Create a twitter thread for it.\n",
    "\"\"\"\n",
    "\n",
    "twitter_thread_template = PromptTemplate(\n",
    "    input_variables=[\"podcast_notes\"],\n",
    "    template=template,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c61a4bd2-9c89-4a8e-bf3d-792cb97369c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\")\n",
    "chain = LLMChain(llm=llm, prompt=podcast_summary_prompt)\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for name, podcast in podcasts_to_analyze.items():\n",
    "  text_splitter = CharacterTextSplitter(        \n",
    "    separator = \". \",\n",
    "    chunk_size = 4000,\n",
    "    chunk_overlap  = 200,\n",
    "    length_function = len,\n",
    "  )\n",
    "  \n",
    "  texts = text_splitter.split_text(podcast)\n",
    "\n",
    "  results = []\n",
    "  \n",
    "  for text in texts:\n",
    "    subset = chain.run(text)\n",
    "    results.append(subset)\n",
    "\n",
    "  with open(\"./podcasts/summary-{}.txt\".format(urllib.parse.quote(file)), \"w\") as f:\n",
    "    joined_text = \"\\n\".join(results)\n",
    "    \n",
    "    f.write(joined_text)\n",
    "    \n",
    "    collection.add(\n",
    "      documents=[text],\n",
    "      ids=[file]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69d06a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:> [build_index_from_documents] Total LLM token usage: 0 tokens\n",
      "INFO:root:> [build_index_from_documents] Total embedding token usage: 5102 tokens\n",
      "INFO:root:> [build_index_from_documents] Total LLM token usage: 0 tokens\n",
      "INFO:root:> [build_index_from_documents] Total embedding token usage: 4942 tokens\n"
     ]
    }
   ],
   "source": [
    "from gpt_index import SimpleDirectoryReader, GPTSimpleVectorIndex, LLMPredictor, PromptHelper\n",
    "\n",
    "documents = SimpleDirectoryReader('podcasts').load_data()\n",
    "index = GPTSimpleVectorIndex(documents)\n",
    "\n",
    "# define LLM\n",
    "llm_predictor = LLMPredictor(llm=OpenAI(temperature=0, model_name=\"text-davinci-003\"))\n",
    "\n",
    "# set maximum input size\n",
    "max_input_size = 4096\n",
    "# set number of output tokens\n",
    "num_output = 256\n",
    "# set maximum chunk overlap\n",
    "max_chunk_overlap = 20\n",
    "prompt_helper = PromptHelper(max_input_size, num_output, max_chunk_overlap)\n",
    "\n",
    "index = GPTSimpleVectorIndex(\n",
    "    documents, llm_predictor=llm_predictor, prompt_helper=prompt_helper\n",
    ")\n",
    "\n",
    "index.save_to_disk('index.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c7cf7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = GPTSimpleVectorIndex.load_from_disk('index.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7ca5a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:> [query] Total LLM token usage: 4123 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 5 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. What has been happening since the event three years ago?\n",
      "2. How is the national conversation for you?\n",
      "3. How many investments do you have?\n",
      "4. What makes a Sam Altman deal?\n",
      "5. What have been your most successful investments to date?\n",
      "6. Why did you switch from Boom Supersonic to Hermius?\n",
      "7. Is Hermius climate friendly?\n",
      "8. What are the impacts of us traveling around the world much faster?\n",
      "9. What is going on with Worldcoin?\n",
      "10. Do you know Sam Bankman-Fried?\n",
      "11. Are you interested in crypto more broadly?\n",
      "12. What is your opinion of Sam Bankman-Fried?\n",
      "13. What interests you about Worldcoin?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = index.query(\"What questions were asked?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6caca6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:> [query] Total LLM token usage: 3900 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 10 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "His answer on his most successful investments was that his most successful investments on a multiple spaces was probably Stripe, which was his second investment ever. He also mentioned that he has been doing this for 17 years and has had a lot of really good investments, including a smattering of crypto investments. He mentioned that he is not particularly interested in crypto investments, but is interested in Worldcoin not because it is crypto, but because of the team and the product.\n"
     ]
    }
   ],
   "source": [
    "response = index.query(\"What was his answer on his most successful investments??\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
