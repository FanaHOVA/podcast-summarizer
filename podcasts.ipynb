{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "712fdefe-b4a9-4244-9c37-74cb3a179187",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-1.5.3-cp310-cp310-macosx_11_0_arm64.whl (10.9 MB)\n",
      "Collecting langchain\n",
      "  Using cached langchain-0.0.87-py3-none-any.whl (253 kB)\n",
      "Collecting yt-dlp\n",
      "  Using cached yt_dlp-2023.1.6-py2.py3-none-any.whl (2.8 MB)\n",
      "Collecting openai-whisper\n",
      "  Using cached openai_whisper-20230124-py3-none-any.whl\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-0.21.1-py3-none-any.whl (19 kB)\n",
      "Collecting openai\n",
      "  Using cached openai-0.26.5-py3-none-any.whl\n",
      "Collecting tiktoken\n",
      "  Using cached tiktoken-0.2.0-cp310-cp310-macosx_11_0_arm64.whl (699 kB)\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.24.2-cp310-cp310-macosx_11_0_arm64.whl (13.9 MB)\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-0.3.0-py3-none-any.whl (36 kB)\n",
      "Collecting python-dateutil>=2.8.1\n",
      "  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n",
      "Collecting pydantic<2,>=1\n",
      "  Using cached pydantic-1.10.5-cp310-cp310-macosx_11_0_arm64.whl (2.5 MB)\n",
      "Collecting requests<3,>=2\n",
      "  Using cached requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "Collecting tenacity<9.0.0,>=8.1.0\n",
      "  Using cached tenacity-8.2.1-py3-none-any.whl (24 kB)\n",
      "Collecting PyYAML<7,>=6\n",
      "  Using cached PyYAML-6.0-cp310-cp310-macosx_11_0_arm64.whl (173 kB)\n",
      "Collecting dataclasses-json<0.6.0,>=0.5.7\n",
      "  Using cached dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3\n",
      "  Using cached aiohttp-3.8.4-cp310-cp310-macosx_11_0_arm64.whl (336 kB)\n",
      "Collecting SQLAlchemy<2,>=1\n",
      "  Using cached SQLAlchemy-1.4.46-cp310-cp310-macosx_12_0_arm64.whl\n",
      "Collecting certifi\n",
      "  Using cached certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "Collecting brotli\n",
      "  Using cached Brotli-1.0.9-cp310-cp310-macosx_10_9_universal2.whl (786 kB)\n",
      "Collecting mutagen\n",
      "  Using cached mutagen-1.46.0-py3-none-any.whl (193 kB)\n",
      "Collecting pycryptodomex\n",
      "  Using cached pycryptodomex-3.17-cp35-abi3-macosx_10_9_universal2.whl (2.4 MB)\n",
      "Collecting websockets\n",
      "  Using cached websockets-10.4-cp310-cp310-macosx_11_0_arm64.whl (97 kB)\n",
      "Collecting transformers>=4.19.0\n",
      "  Using cached transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "Collecting torch\n",
      "  Using cached torch-1.13.1-cp310-none-macosx_11_0_arm64.whl (53.2 MB)\n",
      "Collecting more-itertools\n",
      "  Using cached more_itertools-9.0.0-py3-none-any.whl (52 kB)\n",
      "Collecting ffmpeg-python==0.2.0\n",
      "  Using cached ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
      "Collecting future\n",
      "  Using cached future-0.18.3-py3-none-any.whl\n",
      "Collecting regex>=2022.1.18\n",
      "  Using cached regex-2022.10.31-cp310-cp310-macosx_11_0_arm64.whl (287 kB)\n",
      "Collecting blobfile>=2\n",
      "  Using cached blobfile-2.0.1-py3-none-any.whl (73 kB)\n",
      "Collecting joblib\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Collecting click\n",
      "  Using cached click-8.1.3-py3-none-any.whl (96 kB)\n",
      "Collecting duckdb~=0.5.1\n",
      "  Using cached duckdb-0.5.1-cp310-cp310-macosx_11_0_arm64.whl (14.1 MB)\n",
      "Collecting uvicorn[standard]~=0.18.3\n",
      "  Using cached uvicorn-0.18.3-py3-none-any.whl (57 kB)\n",
      "Collecting sentence-transformers~=2.2.2\n",
      "  Using cached sentence_transformers-2.2.2-py3-none-any.whl\n",
      "Collecting hnswlib~=0.7\n",
      "  Using cached hnswlib-0.7.0-cp310-cp310-macosx_12_0_arm64.whl\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.21.6-cp310-cp310-macosx_11_0_arm64.whl (12.4 MB)\n",
      "Collecting clickhouse-connect~=0.5.7\n",
      "  Using cached clickhouse_connect-0.5.11-cp310-cp310-macosx_11_0_arm64.whl (215 kB)\n",
      "Collecting fastapi~=0.85.1\n",
      "  Using cached fastapi-0.85.2-py3-none-any.whl (55 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.8.2-cp310-cp310-macosx_11_0_arm64.whl (57 kB)\n",
      "Collecting charset-normalizer<4.0,>=2.0\n",
      "  Using cached charset_normalizer-3.0.1-cp310-cp310-macosx_11_0_arm64.whl (122 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting attrs>=17.3.0\n",
      "  Using cached attrs-22.2.0-py3-none-any.whl (60 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.4-cp310-cp310-macosx_11_0_arm64.whl (29 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.3.3-cp310-cp310-macosx_11_0_arm64.whl (34 kB)\n",
      "Collecting urllib3<3,>=1.25.3\n",
      "  Using cached urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
      "Collecting lxml~=4.9\n",
      "  Using cached lxml-4.9.2-cp310-cp310-macosx_12_0_arm64.whl\n",
      "Collecting filelock~=3.0\n",
      "  Using cached filelock-3.9.0-py3-none-any.whl (9.7 kB)\n",
      "Collecting zstandard\n",
      "  Using cached zstandard-0.19.0-cp310-cp310-macosx_11_0_arm64.whl (348 kB)\n",
      "Collecting lz4\n",
      "  Using cached lz4-4.3.2-cp310-cp310-macosx_11_0_arm64.whl (212 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.3.0\n",
      "  Using cached marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
      "Collecting marshmallow-enum<2.0.0,>=1.5.1\n",
      "  Using cached marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Collecting typing-inspect>=0.4.0\n",
      "  Using cached typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
      "Collecting starlette==0.20.4\n",
      "  Using cached starlette-0.20.4-py3-none-any.whl (63 kB)\n",
      "Collecting anyio<5,>=3.4.0\n",
      "  Using cached anyio-3.6.2-py3-none-any.whl (80 kB)\n",
      "Collecting typing-extensions>=4.2.0\n",
      "  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting six>=1.5\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.14.1-cp310-cp310-macosx_11_0_arm64.whl (1.3 MB)\n",
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.1.97-cp310-cp310-macosx_11_0_arm64.whl (1.1 MB)\n",
      "Collecting huggingface-hub>=0.4.0\n",
      "  Using cached huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.10.0-cp310-cp310-macosx_12_0_arm64.whl (28.8 MB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.2.1-cp310-cp310-macosx_12_0_arm64.whl (8.4 MB)\n",
      "Collecting packaging>=20.0\n",
      "  Using cached packaging-23.0-py3-none-any.whl (42 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Using cached tokenizers-0.13.2-cp310-cp310-macosx_12_0_arm64.whl (3.7 MB)\n",
      "Collecting h11>=0.8\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Collecting httptools>=0.4.0\n",
      "  Using cached httptools-0.5.0-cp310-cp310-macosx_10_9_universal2.whl (228 kB)\n",
      "Collecting watchfiles>=0.13\n",
      "  Using cached watchfiles-0.18.1-cp37-abi3-macosx_11_0_arm64.whl (367 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0\n",
      "  Using cached uvloop-0.17.0-cp310-cp310-macosx_10_9_universal2.whl (2.1 MB)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0\n",
      "  Using cached Pillow-9.4.0-cp310-cp310-macosx_11_0_arm64.whl (3.0 MB)\n",
      "Collecting sniffio>=1.1\n",
      "  Using cached sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: tokenizers, sentencepiece, pytz, charset-normalizer, brotli, zstandard, websockets, uvloop, urllib3, typing-extensions, tqdm, threadpoolctl, tenacity, SQLAlchemy, sniffio, six, regex, PyYAML, python-dotenv, pycryptodomex, pillow, packaging, numpy, mypy-extensions, mutagen, multidict, more-itertools, lz4, lxml, joblib, idna, httptools, h11, future, frozenlist, filelock, click, certifi, attrs, async-timeout, yt-dlp, yarl, uvicorn, typing-inspect, torch, scipy, requests, python-dateutil, pydantic, nltk, marshmallow, hnswlib, ffmpeg-python, duckdb, clickhouse-connect, blobfile, anyio, aiosignal, watchfiles, torchvision, tiktoken, starlette, scikit-learn, pandas, marshmallow-enum, huggingface-hub, aiohttp, transformers, openai, fastapi, dataclasses-json, sentence-transformers, openai-whisper, langchain, chromadb\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.2\n",
      "    Uninstalling tokenizers-0.13.2:\n",
      "      Successfully uninstalled tokenizers-0.13.2\n",
      "  Attempting uninstall: sentencepiece\n",
      "    Found existing installation: sentencepiece 0.1.97\n",
      "    Uninstalling sentencepiece-0.1.97:\n",
      "      Successfully uninstalled sentencepiece-0.1.97\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2022.7.1\n",
      "    Uninstalling pytz-2022.7.1:\n",
      "      Successfully uninstalled pytz-2022.7.1\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 3.0.1\n",
      "    Uninstalling charset-normalizer-3.0.1:\n",
      "      Successfully uninstalled charset-normalizer-3.0.1\n",
      "  Attempting uninstall: brotli\n",
      "    Found existing installation: Brotli 1.0.9\n",
      "    Uninstalling Brotli-1.0.9:\n",
      "      Successfully uninstalled Brotli-1.0.9\n",
      "  Attempting uninstall: zstandard\n",
      "    Found existing installation: zstandard 0.19.0\n",
      "    Uninstalling zstandard-0.19.0:\n",
      "      Successfully uninstalled zstandard-0.19.0\n",
      "  Attempting uninstall: websockets\n",
      "    Found existing installation: websockets 10.4\n",
      "    Uninstalling websockets-10.4:\n",
      "      Successfully uninstalled websockets-10.4\n",
      "  Attempting uninstall: uvloop\n",
      "    Found existing installation: uvloop 0.17.0\n",
      "    Uninstalling uvloop-0.17.0:\n",
      "      Successfully uninstalled uvloop-0.17.0\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.14\n",
      "    Uninstalling urllib3-1.26.14:\n",
      "      Successfully uninstalled urllib3-1.26.14\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.5.0\n",
      "    Uninstalling typing_extensions-4.5.0:\n",
      "      Successfully uninstalled typing_extensions-4.5.0\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.64.1\n",
      "    Uninstalling tqdm-4.64.1:\n",
      "      Successfully uninstalled tqdm-4.64.1\n",
      "  Attempting uninstall: threadpoolctl\n",
      "    Found existing installation: threadpoolctl 3.1.0\n",
      "    Uninstalling threadpoolctl-3.1.0:\n",
      "      Successfully uninstalled threadpoolctl-3.1.0\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 8.2.1\n",
      "    Uninstalling tenacity-8.2.1:\n",
      "      Successfully uninstalled tenacity-8.2.1\n",
      "  Attempting uninstall: SQLAlchemy\n",
      "    Found existing installation: SQLAlchemy 1.4.46\n",
      "    Uninstalling SQLAlchemy-1.4.46:\n",
      "      Successfully uninstalled SQLAlchemy-1.4.46\n",
      "  Attempting uninstall: sniffio\n",
      "    Found existing installation: sniffio 1.3.0\n",
      "    Uninstalling sniffio-1.3.0:\n",
      "      Successfully uninstalled sniffio-1.3.0\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2022.10.31\n",
      "    Uninstalling regex-2022.10.31:\n",
      "      Successfully uninstalled regex-2022.10.31\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n",
      "      Successfully uninstalled PyYAML-6.0\n",
      "  Attempting uninstall: python-dotenv\n",
      "    Found existing installation: python-dotenv 0.21.1\n",
      "    Uninstalling python-dotenv-0.21.1:\n",
      "      Successfully uninstalled python-dotenv-0.21.1\n",
      "  Attempting uninstall: pycryptodomex\n",
      "    Found existing installation: pycryptodomex 3.17\n",
      "    Uninstalling pycryptodomex-3.17:\n",
      "      Successfully uninstalled pycryptodomex-3.17\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: Pillow 9.4.0\n",
      "    Uninstalling Pillow-9.4.0:\n",
      "      Successfully uninstalled Pillow-9.4.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.0\n",
      "    Uninstalling packaging-23.0:\n",
      "      Successfully uninstalled packaging-23.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.6\n",
      "    Uninstalling numpy-1.21.6:\n",
      "      Successfully uninstalled numpy-1.21.6\n",
      "  Attempting uninstall: mypy-extensions\n",
      "    Found existing installation: mypy-extensions 1.0.0\n",
      "    Uninstalling mypy-extensions-1.0.0:\n",
      "      Successfully uninstalled mypy-extensions-1.0.0\n",
      "  Attempting uninstall: mutagen\n",
      "    Found existing installation: mutagen 1.46.0\n",
      "    Uninstalling mutagen-1.46.0:\n",
      "      Successfully uninstalled mutagen-1.46.0\n",
      "  Attempting uninstall: multidict\n",
      "    Found existing installation: multidict 6.0.4\n",
      "    Uninstalling multidict-6.0.4:\n",
      "      Successfully uninstalled multidict-6.0.4\n",
      "  Attempting uninstall: more-itertools\n",
      "    Found existing installation: more-itertools 9.0.0\n",
      "    Uninstalling more-itertools-9.0.0:\n",
      "      Successfully uninstalled more-itertools-9.0.0\n",
      "  Attempting uninstall: lz4\n",
      "    Found existing installation: lz4 4.3.2\n",
      "    Uninstalling lz4-4.3.2:\n",
      "      Successfully uninstalled lz4-4.3.2\n",
      "  Attempting uninstall: lxml\n",
      "    Found existing installation: lxml 4.9.2\n",
      "    Uninstalling lxml-4.9.2:\n",
      "      Successfully uninstalled lxml-4.9.2\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.2.0\n",
      "    Uninstalling joblib-1.2.0:\n",
      "      Successfully uninstalled joblib-1.2.0\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.4\n",
      "    Uninstalling idna-3.4:\n",
      "      Successfully uninstalled idna-3.4\n",
      "  Attempting uninstall: httptools\n",
      "    Found existing installation: httptools 0.5.0\n",
      "    Uninstalling httptools-0.5.0:\n",
      "      Successfully uninstalled httptools-0.5.0\n",
      "  Attempting uninstall: h11\n",
      "    Found existing installation: h11 0.14.0\n",
      "    Uninstalling h11-0.14.0:\n",
      "      Successfully uninstalled h11-0.14.0\n",
      "  Attempting uninstall: future\n",
      "    Found existing installation: future 0.18.3\n",
      "    Uninstalling future-0.18.3:\n",
      "      Successfully uninstalled future-0.18.3\n",
      "  Attempting uninstall: frozenlist\n",
      "    Found existing installation: frozenlist 1.3.3\n",
      "    Uninstalling frozenlist-1.3.3:\n",
      "      Successfully uninstalled frozenlist-1.3.3\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.9.0\n",
      "    Uninstalling filelock-3.9.0:\n",
      "      Successfully uninstalled filelock-3.9.0\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.1.3\n",
      "    Uninstalling click-8.1.3:\n",
      "      Successfully uninstalled click-8.1.3\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2022.12.7\n",
      "    Uninstalling certifi-2022.12.7:\n",
      "      Successfully uninstalled certifi-2022.12.7\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 22.2.0\n",
      "    Uninstalling attrs-22.2.0:\n",
      "      Successfully uninstalled attrs-22.2.0\n",
      "  Attempting uninstall: async-timeout\n",
      "    Found existing installation: async-timeout 4.0.2\n",
      "    Uninstalling async-timeout-4.0.2:\n",
      "      Successfully uninstalled async-timeout-4.0.2\n",
      "  Attempting uninstall: yt-dlp\n",
      "    Found existing installation: yt-dlp 2023.1.6\n",
      "    Uninstalling yt-dlp-2023.1.6:\n",
      "      Successfully uninstalled yt-dlp-2023.1.6\n",
      "  Attempting uninstall: yarl\n",
      "    Found existing installation: yarl 1.8.2\n",
      "    Uninstalling yarl-1.8.2:\n",
      "      Successfully uninstalled yarl-1.8.2\n",
      "  Attempting uninstall: uvicorn\n",
      "    Found existing installation: uvicorn 0.18.3\n",
      "    Uninstalling uvicorn-0.18.3:\n",
      "      Successfully uninstalled uvicorn-0.18.3\n",
      "  Attempting uninstall: typing-inspect\n",
      "    Found existing installation: typing-inspect 0.8.0\n",
      "    Uninstalling typing-inspect-0.8.0:\n",
      "      Successfully uninstalled typing-inspect-0.8.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.13.1\n",
      "    Uninstalling torch-1.13.1:\n",
      "      Successfully uninstalled torch-1.13.1\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.10.0\n",
      "    Uninstalling scipy-1.10.0:\n",
      "      Successfully uninstalled scipy-1.10.0\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.28.2\n",
      "    Uninstalling requests-2.28.2:\n",
      "      Successfully uninstalled requests-2.28.2\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.2\n",
      "    Uninstalling python-dateutil-2.8.2:\n",
      "      Successfully uninstalled python-dateutil-2.8.2\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.5\n",
      "    Uninstalling pydantic-1.10.5:\n",
      "      Successfully uninstalled pydantic-1.10.5\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.8.1\n",
      "    Uninstalling nltk-3.8.1:\n",
      "      Successfully uninstalled nltk-3.8.1\n",
      "  Attempting uninstall: marshmallow\n",
      "    Found existing installation: marshmallow 3.19.0\n",
      "    Uninstalling marshmallow-3.19.0:\n",
      "      Successfully uninstalled marshmallow-3.19.0\n",
      "  Attempting uninstall: hnswlib\n",
      "    Found existing installation: hnswlib 0.7.0\n",
      "    Uninstalling hnswlib-0.7.0:\n",
      "      Successfully uninstalled hnswlib-0.7.0\n",
      "  Attempting uninstall: ffmpeg-python\n",
      "    Found existing installation: ffmpeg-python 0.2.0\n",
      "    Uninstalling ffmpeg-python-0.2.0:\n",
      "      Successfully uninstalled ffmpeg-python-0.2.0\n",
      "  Attempting uninstall: duckdb\n",
      "    Found existing installation: duckdb 0.5.1\n",
      "    Uninstalling duckdb-0.5.1:\n",
      "      Successfully uninstalled duckdb-0.5.1\n",
      "  Attempting uninstall: clickhouse-connect\n",
      "    Found existing installation: clickhouse-connect 0.5.11\n",
      "    Uninstalling clickhouse-connect-0.5.11:\n",
      "      Successfully uninstalled clickhouse-connect-0.5.11\n",
      "  Attempting uninstall: blobfile\n",
      "    Found existing installation: blobfile 2.0.1\n",
      "    Uninstalling blobfile-2.0.1:\n",
      "      Successfully uninstalled blobfile-2.0.1\n",
      "  Attempting uninstall: anyio\n",
      "    Found existing installation: anyio 3.6.2\n",
      "    Uninstalling anyio-3.6.2:\n",
      "      Successfully uninstalled anyio-3.6.2\n",
      "  Attempting uninstall: aiosignal\n",
      "    Found existing installation: aiosignal 1.3.1\n",
      "    Uninstalling aiosignal-1.3.1:\n",
      "      Successfully uninstalled aiosignal-1.3.1\n",
      "  Attempting uninstall: watchfiles\n",
      "    Found existing installation: watchfiles 0.18.1\n",
      "    Uninstalling watchfiles-0.18.1:\n",
      "      Successfully uninstalled watchfiles-0.18.1\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.14.1\n",
      "    Uninstalling torchvision-0.14.1:\n",
      "      Successfully uninstalled torchvision-0.14.1\n",
      "  Attempting uninstall: tiktoken\n",
      "    Found existing installation: tiktoken 0.2.0\n",
      "    Uninstalling tiktoken-0.2.0:\n",
      "      Successfully uninstalled tiktoken-0.2.0\n",
      "  Attempting uninstall: starlette\n",
      "    Found existing installation: starlette 0.20.4\n",
      "    Uninstalling starlette-0.20.4:\n",
      "      Successfully uninstalled starlette-0.20.4\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.2.1\n",
      "    Uninstalling scikit-learn-1.2.1:\n",
      "      Successfully uninstalled scikit-learn-1.2.1\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.5.3\n",
      "    Uninstalling pandas-1.5.3:\n",
      "      Successfully uninstalled pandas-1.5.3\n",
      "  Attempting uninstall: marshmallow-enum\n",
      "    Found existing installation: marshmallow-enum 1.5.1\n",
      "    Uninstalling marshmallow-enum-1.5.1:\n",
      "      Successfully uninstalled marshmallow-enum-1.5.1\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.12.0\n",
      "    Uninstalling huggingface-hub-0.12.0:\n",
      "      Successfully uninstalled huggingface-hub-0.12.0\n",
      "  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.8.4\n",
      "    Uninstalling aiohttp-3.8.4:\n",
      "      Successfully uninstalled aiohttp-3.8.4\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.26.1\n",
      "    Uninstalling transformers-4.26.1:\n",
      "      Successfully uninstalled transformers-4.26.1\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.26.5\n",
      "    Uninstalling openai-0.26.5:\n",
      "      Successfully uninstalled openai-0.26.5\n",
      "  Attempting uninstall: fastapi\n",
      "    Found existing installation: fastapi 0.85.2\n",
      "    Uninstalling fastapi-0.85.2:\n",
      "      Successfully uninstalled fastapi-0.85.2\n",
      "  Attempting uninstall: dataclasses-json\n",
      "    Found existing installation: dataclasses-json 0.5.7\n",
      "    Uninstalling dataclasses-json-0.5.7:\n",
      "      Successfully uninstalled dataclasses-json-0.5.7\n",
      "  Attempting uninstall: sentence-transformers\n",
      "    Found existing installation: sentence-transformers 2.2.2\n",
      "    Uninstalling sentence-transformers-2.2.2:\n",
      "      Successfully uninstalled sentence-transformers-2.2.2\n",
      "  Attempting uninstall: openai-whisper\n",
      "    Found existing installation: openai-whisper 20230124\n",
      "    Uninstalling openai-whisper-20230124:\n",
      "      Successfully uninstalled openai-whisper-20230124\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.0.87\n",
      "    Uninstalling langchain-0.0.87:\n",
      "      Successfully uninstalled langchain-0.0.87\n",
      "  Attempting uninstall: chromadb\n",
      "    Found existing installation: chromadb 0.3.0\n",
      "    Uninstalling chromadb-0.3.0:\n",
      "      Successfully uninstalled chromadb-0.3.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gpt-index 0.4.1 requires tenacity<8.2.0, but you have tenacity 8.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PyYAML-6.0 SQLAlchemy-1.4.46 aiohttp-3.8.4 aiosignal-1.3.1 anyio-3.6.2 async-timeout-4.0.2 attrs-22.2.0 blobfile-2.0.1 brotli-1.0.9 certifi-2022.12.7 charset-normalizer-3.0.1 chromadb-0.3.0 click-8.1.3 clickhouse-connect-0.5.11 dataclasses-json-0.5.7 duckdb-0.5.1 fastapi-0.85.2 ffmpeg-python-0.2.0 filelock-3.9.0 frozenlist-1.3.3 future-0.18.3 h11-0.14.0 hnswlib-0.7.0 httptools-0.5.0 huggingface-hub-0.12.0 idna-3.4 joblib-1.2.0 langchain-0.0.87 lxml-4.9.2 lz4-4.3.2 marshmallow-3.19.0 marshmallow-enum-1.5.1 more-itertools-9.0.0 multidict-6.0.4 mutagen-1.46.0 mypy-extensions-1.0.0 nltk-3.8.1 numpy-1.21.6 openai-0.26.5 openai-whisper-20230124 packaging-23.0 pandas-1.5.3 pillow-9.4.0 pycryptodomex-3.17 pydantic-1.10.5 python-dateutil-2.8.2 python-dotenv-0.21.1 pytz-2022.7.1 regex-2022.10.31 requests-2.28.2 scikit-learn-1.2.1 scipy-1.10.0 sentence-transformers-2.2.2 sentencepiece-0.1.97 six-1.16.0 sniffio-1.3.0 starlette-0.20.4 tenacity-8.2.1 threadpoolctl-3.1.0 tiktoken-0.2.0 tokenizers-0.13.2 torch-1.13.1 torchvision-0.14.1 tqdm-4.64.1 transformers-4.26.1 typing-extensions-4.5.0 typing-inspect-0.8.0 urllib3-1.26.14 uvicorn-0.18.3 uvloop-0.17.0 watchfiles-0.18.1 websockets-10.4 yarl-1.8.2 yt-dlp-2023.1.6 zstandard-0.19.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install --force-reinstall -r requirements.txt\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d72b24e-45cf-45fc-b2ca-a947f3e1022f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=57OU18cogJI\n",
      "[youtube] 57OU18cogJI: Downloading webpage\n",
      "[youtube] 57OU18cogJI: Downloading android player API JSON\n",
      "[info] 57OU18cogJI: Downloading 1 format(s): 140\n",
      "[download] ./tmp/foo_StrictlyVC in conversation with Sam Altman, part one-57OU18cogJI.m4a has already been downloaded\n",
      "[download] 100% of   19.02MiB\n",
      "[ExtractAudio] Not converting audio ./tmp/foo_StrictlyVC in conversation with Sam Altman, part one-57OU18cogJI.m4a; file is already in target format m4a\n"
     ]
    }
   ],
   "source": [
    "import yt_dlp\n",
    "\n",
    "URLS = ['https://www.youtube.com/watch?v=57OU18cogJI']\n",
    "\n",
    "ydl_opts = {\n",
    "    'format': 'm4a/bestaudio/best',\n",
    "    'postprocessors': [{\n",
    "        'key': 'FFmpegExtractAudio',\n",
    "        'preferredcodec': 'm4a',\n",
    "    }],\n",
    "    'outtmpl': './tmp/foo_%(title)s-%(id)s.%(ext)s'\n",
    "}\n",
    "\n",
    "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "    error_code = ydl.download(URLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faa60d9e-147d-4914-b94e-b6ce864ca384",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import os\n",
    "import urllib.parse\n",
    "\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "podcasts_to_analyze = {}\n",
    "\n",
    "for file in os.listdir(\"./tmp\"):\n",
    "    # Skip if the file is not a video or audio file\n",
    "    if not file.endswith(\".m4a\"):\n",
    "        continue\n",
    "    \n",
    "    file_path = os.path.join(\"./tmp\", file)\n",
    "    result = model.transcribe(file_path)\n",
    "    podcasts_to_analyze[file] = result[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d617b4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Chroma using direct local API.\n",
      "Using DuckDB in-memory for database. Data will be transient.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "chroma_client = chromadb.Client()\n",
    "\n",
    "collection = chroma_client.get_collection(name=\"oss_podcasts\") or chroma_client.create_collection(name=\"oss_podcasts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ede275e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for file, text in podcasts_to_analyze.items():\n",
    "    with open(f\"./podcasts/{urllib.parse.quote(file)}.txt\", \"w\") as f:\n",
    "        f.write(text)\n",
    "\n",
    "        collection.add(\n",
    "            documents=[text],\n",
    "            ids=[file]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3081ef70-f7c3-47d4-aefc-e1cd2b01aa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "\n",
    "template = \"\"\"\n",
    "Read the transcript of the podcast below:\n",
    " {podcast_contents}\n",
    "\n",
    "Create bullet points with the main topics of the podcast, followed by the opinions of the speakers. \n",
    "\"\"\"\n",
    "\n",
    "podcast_summary_prompt = PromptTemplate(\n",
    "    input_variables=[\"podcast_contents\"],\n",
    "    template=template,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "adcd4686-0856-4392-923d-dce6d5834e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "\n",
    "template = \"\"\"\n",
    "When I listen to a podcast, I take notes on the main talking points of the hosts. I divide it in sections based on topics discussed. \n",
    "If the host mentions a specific technology or product, I note that in double brackets like this: [[artificial intelligence]].\n",
    "\n",
    "These are the notes from the last podcast I listened to:\n",
    "\n",
    "{podcast_notes}\n",
    "\n",
    "Write a {words_count} words summary of the notes.\n",
    "\"\"\"\n",
    "\n",
    "notes_summary_template = PromptTemplate(\n",
    "    input_variables=[\"podcast_notes\", \"words_count\"],\n",
    "    template=template,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9472a7e-ad26-469b-bd99-2904a4ec730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "\n",
    "template = \"\"\"\n",
    "When I take notes for a podcast, I like to also write twitter threads to share them. Each tweet should end saying how far we are in the thread; if it's a 5 tweets thread, the first tweet should end with (1/5), the second one with (2/5), etc.\n",
    "\n",
    "The tweets have to be easy to read and catch people's attention. Each of them should include an emoji.\n",
    "\n",
    "These are the notes from my last podcast:\n",
    "\n",
    "{podcast_notes}\n",
    "\n",
    "Create a twitter thread for it.\n",
    "\"\"\"\n",
    "\n",
    "twitter_thread_template = PromptTemplate(\n",
    "    input_variables=[\"podcast_notes\"],\n",
    "    template=template,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c61a4bd2-9c89-4a8e-bf3d-792cb97369c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\")\n",
    "chain = LLMChain(llm=llm, prompt=podcast_summary_prompt)\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for name, podcast in podcasts_to_analyze.items():\n",
    "  text_splitter = CharacterTextSplitter(        \n",
    "    separator = \". \",\n",
    "    chunk_size = 4000,\n",
    "    chunk_overlap  = 200,\n",
    "    length_function = len,\n",
    "  )\n",
    "  \n",
    "  texts = text_splitter.split_text(podcast)\n",
    "\n",
    "  results = []\n",
    "  \n",
    "  for text in texts:\n",
    "    subset = chain.run(text)\n",
    "    results.append(subset)\n",
    "\n",
    "  with open(\"./podcasts/summary-{}.txt\".format(urllib.parse.quote(file)), \"w\") as f:\n",
    "    joined_text = \"\\n\".join(results)\n",
    "    \n",
    "    f.write(joined_text)\n",
    "    \n",
    "    collection.add(\n",
    "      documents=[text],\n",
    "      ids=[file]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69d06a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sam did not seem to be very interested in crypto, but he did think it could be a useful tool to experiment with global UBI. He also thought that the spirit of the Web 3 people was great, but he did not intuitively understand why they needed it.\n"
     ]
    }
   ],
   "source": [
    "from gpt_index import SimpleDirectoryReader, GPTSimpleVectorIndex, LLMPredictor, PromptHelper\n",
    "\n",
    "documents = SimpleDirectoryReader('podcasts').load_data()\n",
    "index = GPTSimpleVectorIndex(documents)\n",
    "\n",
    "# define LLM\n",
    "llm_predictor = LLMPredictor(llm=OpenAI(temperature=0, model_name=\"text-davinci-003\"))\n",
    "\n",
    "# define prompt helper\n",
    "# set maximum input size\n",
    "max_input_size = 4096\n",
    "# set number of output tokens\n",
    "num_output = 256\n",
    "# set maximum chunk overlap\n",
    "max_chunk_overlap = 20\n",
    "prompt_helper = PromptHelper(max_input_size, num_output, max_chunk_overlap)\n",
    "\n",
    "index = GPTSimpleVectorIndex(\n",
    "    documents, llm_predictor=llm_predictor, prompt_helper=prompt_helper\n",
    ")\n",
    "\n",
    "# save to disk\n",
    "index.save_to_disk('index.json')\n",
    "# load from disk\n",
    "index = GPTSimpleVectorIndex.load_from_disk('index.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7ca5a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sam did not seem to be very interested in crypto, but he did think that it could be a useful tool to experiment with global UBI. He also thought that the spirit of the Web 3 people was great, but he did not intuitively understand why they needed it.\n",
      "\n",
      "He is excited about the progress being made in biotech, the potential for using technology to experiment with global UBI, and the potential for turning adult cells into gametes. He is also excited about the potential for Gary Tankiman to remake Y-Combinator in the current market, and the potential for startups to create great value in the current market.\n"
     ]
    }
   ],
   "source": [
    "response = index.query(\"What did Sam think of crypto?\")\n",
    "print(response)\n",
    "\n",
    "response = index.query(\"What is he excited about in technology?\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
